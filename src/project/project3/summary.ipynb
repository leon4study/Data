{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from yellowbrick.cluster import KElbowVisualizer\n",
    "# k 값 참고: distance map 라이브러리 import \n",
    "from yellowbrick.cluster import intercluster_distance\n",
    "\n",
    "# k 값 참고: 실루엣 계수 확인을 위한 라이브러리 import \n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/Users/jun/GitStudy/Data_4/Data/eCommerce3'\n",
    "os.chdir(data_path)\n",
    "orders = pd.read_csv('orders.csv')\n",
    "orders.dropna(subset=['order_approved_at','order_delivered_timestamp'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 형식 바꾸기\n",
    "orders['order_purchase_timestamp'] = pd.to_datetime(orders['order_purchase_timestamp'], errors = 'coerce')\n",
    "orders['order_approved_at'] = pd.to_datetime(orders['order_approved_at'], errors = 'coerce')\n",
    "orders['order_delivered_timestamp'] = pd.to_datetime(orders['order_delivered_timestamp'], errors = 'coerce')\n",
    "orders['order_estimated_delivery_date'] = pd.to_datetime(orders['order_estimated_delivery_date'], errors = 'coerce')\n",
    "\n",
    "# 날짜 데이터 이상치확인\n",
    "# 역방향이면 이상치로 의심\n",
    "Check_date_outliers = orders[\n",
    "    (orders['order_purchase_timestamp'] > orders['order_approved_at']) |\n",
    "    (orders['order_approved_at'] > orders['order_delivered_timestamp'])\n",
    "]\n",
    "out_ids = Check_date_outliers['order_id'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleaned_df = pd.read_csv('capstone_data_cleaned.csv')\n",
    "#item_id, customer_zip_code_prefix 숫자에서 문자열로 변경\n",
    "data_cleaned_df['order_item_id'] = data_cleaned_df['order_item_id'].astype(str)\n",
    "data_cleaned_df['customer_zip_code_prefix'] = data_cleaned_df['customer_zip_code_prefix'].astype(str)\n",
    "# to_datetime\n",
    "data_cleaned_df['order_purchase_timestamp'] = pd.to_datetime(data_cleaned_df['order_purchase_timestamp'])\n",
    "data_cleaned_df['order_delivered_timestamp'] = pd.to_datetime(data_cleaned_df['order_delivered_timestamp'])\n",
    "data_cleaned_df['order_approved_at']=pd.to_datetime(data_cleaned_df['order_approved_at'])\n",
    "data_cleaned_df['order_estimated_delivery_date'] = pd.to_datetime(data_cleaned_df['order_estimated_delivery_date'])\n",
    "# payment\n",
    "data_cleaned_df['total_payment'] = data_cleaned_df['price'] + data_cleaned_df['shipping_charges']\n",
    "# volume\n",
    "data_cleaned_df['volume'] = data_cleaned_df['product_height_cm'] * data_cleaned_df['product_length_cm'] * data_cleaned_df['product_width_cm']\n",
    "\n",
    "# 안 쓰는 행 삭제\n",
    "columns_to_remove = ['order_estimated_delivery_date', 'shipping_charges', 'price', 'payment_value','customer_city','order_approved_at']\n",
    "\n",
    "retail_df = data_cleaned_df.drop(columns=columns_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "electronics =  [\n",
    "        \"audio\", \"computers_accessories\", \"electronics\", \n",
    "        \"telephony\", \"tablets_printing_image\", \"computers\", \"cine_photo\",  \n",
    "        \"dvds_blu_ray\", \"fixed_telephony\",\"consoles_games\"]\n",
    "\n",
    "food = [\"food\", \"drinks\", \"food_drink\", \"la_cuisine\"]\n",
    "\n",
    "\n",
    "toys = [\"toys\"]\n",
    "\n",
    "home_appliances =[ \"home_appliances\", \"home_appliances_2\" ]\n",
    "\n",
    "furniture = [\n",
    "        \"housewares\", \"furniture_decor\", \"bed_bath_table\",\n",
    "        \"kitchen_dining_laundry_garden_furniture\", \n",
    "        \"furniture_living_room\", \"furniture_bedroom\",\n",
    "        \"furniture_mattress_and_upholstery\", \"home_confort\", \"home_comfort_2\", \n",
    "        \"office_furniture\"]\n",
    "\n",
    "construction = [\"costruction_tools_tools\", \"construction_tools_lights\",\"construction_tools_safety\", \"home_construction\", \"construction_tools_construction\"]\n",
    "\n",
    "fashion_beauty = [\n",
    "        \"fashion_bags_accessories\", \"fashion_shoes\", \"fashion_male_clothing\", \"watches_gifts\",\n",
    "        \"fashio_female_clothing\", \"fashion_childrens_clothes\", \n",
    "        \"fashion_underwear_beach\", \"fashion_sport\",\"cool_stuff\", \"health_beauty\", \"perfumery\",\"luggage_accessories\",\"sports_leisure\"\n",
    "    ]\n",
    "\n",
    "baby_products = [ \"baby\",\"diapers_and_hygiene\"]\n",
    "\n",
    "arts_hobbies =  [ \"art\", \"arts_and_craftmanship\", \"music\", \"musical_instruments\", \n",
    "                \"books_general_interest\", \"books_technical\", \"books_imported\", \n",
    "        \"christmas_supplies\", \"stationery\", \"party_supplies\",\"garden_tools\",\"flowers\",\"costruction_tools_garden\"]\n",
    "\n",
    "industry = [\"industry_commerce_and_business\", \"agro_industry_and_commerce\", \"market_place\"]\n",
    "\n",
    "security = [\"signaling_and_security\", \"security_and_services\" ]\n",
    "others = [\"pet_shop\",\"auto\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_product(row):\n",
    "    if row in electronics:\n",
    "        return 'electronics'\n",
    "    elif row in food:\n",
    "        return 'food'\n",
    "    elif row in toys:\n",
    "        return 'toys'\n",
    "    elif row in home_appliances:\n",
    "        return 'home_appliances'\n",
    "    elif row in furniture:\n",
    "        return 'furniture'\n",
    "    elif row in construction:\n",
    "        return 'construction'\n",
    "    elif row in fashion_beauty:\n",
    "        return 'fashion_beauty'\n",
    "    elif row in baby_products:\n",
    "        return 'baby_products'\n",
    "    elif row in arts_hobbies:\n",
    "        return 'arts_hobbies'\n",
    "    elif row in industry:\n",
    "        return 'industry'\n",
    "    elif row in security:\n",
    "        return 'security'\n",
    "    else:\n",
    "        return 'others'\n",
    "\n",
    "# retail['product_category_name'] 컬럼을 새로운 카테고리로 분류\n",
    "retail_df['category'] = retail_df['product_category_name'].apply(categorize_product)\n",
    "retail_df = retail_df.drop(columns='product_category_name')\n",
    "retail_df = retail_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payment_list = sorted(retail_df['payment_type'].unique())\n",
    "\n",
    "# 그룹화된 payment_type을 sorted된 순서로 결합\n",
    "result = (\n",
    "    retail_df[['order_id', 'payment_type']]\n",
    "    .groupby('order_id')['payment_type']\n",
    "    .apply(lambda x: '/'.join(sorted(set(x), key=lambda y: payment_list.index(y))))\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# retail_df 에 있는 payment_type 을 지우고 order_id로 groupby\n",
    "retail_cleaned = retail_df.drop(columns='payment_type')\n",
    "retail_grouped = retail_cleaned.groupby('order_id').first().reset_index()\n",
    "\n",
    "# 아까 만든 id 별 payment_type 테이블과 join\n",
    "merged_df = result.merge(retail_grouped, on='order_id', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#deliverd_\n",
    "merged_df['delivery_hours'] = (merged_df['order_delivered_timestamp'] - merged_df['order_purchase_timestamp']).dt.total_seconds() //3600  \n",
    "merged_df = merged_df.drop(columns='order_delivered_timestamp')\n",
    "\n",
    "\n",
    "# 가장 최근 구매 건을 기준으로 해당 아이템의 구매가 얼마나 오래 되었는지 나타내는 # Recency column 추가\n",
    "max_date = max(retail_df['order_purchase_timestamp']) #최근 구매\n",
    "merged_df['Diff_days'] = (max_date - merged_df['order_purchase_timestamp']).dt.days + 1\n",
    "merged_df = merged_df.drop(columns='order_purchase_timestamp')\n",
    "merged_df =merged_df[merged_df['Diff_days'] <= 365 ]\n",
    "\n",
    "#Loyal: 3개월 이내 (자주 구매/활성화 고객).\n",
    "#Potential: 3-6개월 (재활성화 가능성 있는 고객).\n",
    "#At Risk: 6-9개월 (이탈 위험 고객).\n",
    "#Lost: 9-12개월 (거의 이탈한 고객).\n",
    "\n",
    "def diff_type(n):\n",
    "    n = (n-1)//91 \n",
    "    if n < 1 : \n",
    "        return 'loyal'\n",
    "    elif n < 2:\n",
    "        return 'potential'\n",
    "    elif n < 3:\n",
    "        return 'at_risk'\n",
    "    else :\n",
    "        return 'lost'\n",
    "\n",
    "merged_df['Diff_type'] = merged_df['Diff_days'].apply(diff_type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가로세로높이 부피로으로 통합했으니 삭제\n",
    "merged_df2 = merged_df.drop(columns=['product_length_cm','product_height_cm','product_width_cm'])\n",
    "\n",
    "# 화영님이 넣으신 이상치에 out_ids ID들 삭제\n",
    "# 'order_id' 열의 값이 out_ids에 포함된 행 삭제\n",
    "merged_df2 = merged_df2[~merged_df2['order_id'].isin(out_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 클러스터링 할 컬럼 지정\n",
    "feature_names = ['payment_type','product_weight_g', 'total_payment', 'volume', 'category', 'Diff_days']\n",
    "\n",
    "merged_df_f = pd.DataFrame(merged_df2 , columns=feature_names)\n",
    "encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "\n",
    "# 인코딩 할 컬럼 지정 (범주형)\n",
    "columns_to_encode = ['payment_type', 'category']\n",
    "\n",
    "# 원-핫 인코딩 수행\n",
    "encoded_data = encoder.fit_transform(merged_df_f[columns_to_encode])\n",
    "\n",
    "# 원-핫 인코딩된 컬럼 이름 생성\n",
    "encoded_columns = encoder.get_feature_names_out(columns_to_encode)\n",
    "\n",
    "# 결과를 DataFrame으로 변환\n",
    "encoded_df = pd.DataFrame(encoded_data, columns=encoded_columns)\n",
    "\n",
    "# 기존 컬럼과 병합 (인코딩 제외한 나머지 컬럼 추가)\n",
    "merged_result = pd.concat([merged_df_f.drop(columns=columns_to_encode).reset_index(drop=True), encoded_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원핫 인코딩되지 않은 컬럼 선택\n",
    "columns_to_scale = merged_result.columns.difference(encoded_columns)\n",
    "\n",
    "# 스케일링 대상 데이터 추출\n",
    "data_to_scale = merged_result[columns_to_scale]\n",
    "\n",
    "# StandardScaler 초기화 및 스케일링\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(data_to_scale)\n",
    "\n",
    "# 스케일링 결과를 DataFrame으로 변환\n",
    "scaled_df = pd.DataFrame(scaled_data, columns=columns_to_scale, index=merged_result.index)\n",
    "\n",
    "# 스케일링된 데이터와 원핫 인코딩된 데이터 병합\n",
    "final_result = pd.concat([scaled_df, merged_result[encoded_columns]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# 주성분 개수를 판단하기 위한 pca임의 시행 \n",
    "pca = PCA(n_components=6)\n",
    "pca.fit(final_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca 시행\n",
    "pca_df = pca.fit_transform(final_result)\n",
    "pca_df = pd.DataFrame(data = pca_df, columns = ['PC1','PC2','PC3','PC4','PC5','PC6']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 군집개수(n_cluster)는 5,초기 중심 설정방식 랜덤,  \n",
    "kmeans = KMeans(n_clusters=4, random_state=42, init='random')\n",
    "\n",
    "# pca df 를 이용한 kmeans 알고리즘 적용\n",
    "kmeans.fit(pca_df)\n",
    "\n",
    "# 클러스터 번호 가져오기 \n",
    "labels = kmeans.labels_\n",
    "\n",
    "# 클러스터 번호를 PCA 데이터프레임에 추가하기\n",
    "# 클러스터 번호가 할당된 데이터셋 생성\n",
    "# 이제 pca_df의 마지막 컬럼(Cluster)에는 각 데이터 포인트가 속한 클러스터 번호가 포함되어 있습니다.\n",
    "kmeans_df = pd.concat([pca_df, pd.DataFrame({'Cluster':labels})],axis = 1)\n",
    "\n",
    "# PCA 데이터프레임에 클러스터 번호 추가\n",
    "pca_df['Cluster'] = labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 클러스터 번호가 할당된 데이터셋 생성\n",
    "kmeans_df.groupby(['Cluster'])['PC1'].count().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_centers = kmeans.cluster_centers_\n",
    "print(pd.DataFrame(cluster_centers, columns=['PC1', 'PC2', 'PC3', 'PC4', 'PC5', 'PC6']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "leo4study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
